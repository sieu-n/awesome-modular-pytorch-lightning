# Implement supervised procedure in the paper:
# 3D Human Pose Estimation with Spatial and Temporal Transformers

name: "3D-Pose-Estimation-PoseFormer"

debug:
  network_summary:
    input_shape: [17, 2, "{const.receptive_field}"]

dataloader:
  base_dataloader:
    batch_size: 1024

training:
  ID: "PoseLiftingTrainer"

  epochs: 80
  lr: 0.001

  get_decoded: false

  optimizer: "adam"
  optimizer_cfg:
    lr: "{training.lr}"
    weight_decay: 0.0
    amsgrad: True

  lr_scheduler:
    name: "cosine"
    args:
      T_max: "{training.epochs}"
    cfg:
      interval: "epoch"
  metrics:
    # TODO
    # protocol 1
    loss:
      when: "trn"
      name: TorchMetric
      args:
        name: "MeanMetric"
      update:
        value: "loss"
    # compute action-wise MPJPE loss
    mpjpe:
      when: "val,test"
      name: SubsetMetric
      args:
        name: MPJPE
        num_subsets: 15 # number of actions
        get_avg: True

      update:
        reconstructed_joints: "reconstruction_global"
        gt_joints: "joints_gt_global"
        subset: "action_idx"
    # protocol 2
    #pmpjpe:
    # protocol 3
    #nmpjpe:

callbacks:
  ModelCheckpoint:
    name: LightningCallback
    args:
      name: ModelCheckpoint
      args:
        monitor: "epoch_val/mpjpe"
        mode: "max"
        save_last: True
        save_top_k: 1
  LearningRateMonitor:
    name: LightningCallback
    args:
      name: "LearningRateMonitor"
      args:
        logging_interval: "epoch"

model:
  modules:
    backbone:
      name: "PoseTransformer"
      args:
        num_frame: 
        num_joints: "{const.num_joints}"
        in_chans: 2
        embed_dim_ratio: 32
        depth: 4
        num_heads: 8
        mlp_ratio: 2.
        qkv_bias: True
        qk_scale: null
        drop_path_rate: 0.1
    loss_fn:
      name: "MSELoss"
wandb:
  project: "human36m-3d-pose-estimation-temporal"

const:
  receptive_field: 81
