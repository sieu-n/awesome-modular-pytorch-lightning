const:
  num_gpus: "len({trainer.gpus})"
  samples_per_gpu: 2 # NOTE this is train batch size!!
  val_samples_per_gpu: 1 # NOTE this is val batch size!!

trainer:
  # evaluate every 3 epochs
  check_val_every_n_epoch: 3

training:
  metrics:
    mAP:
      when: "val,test"
      name: MMDet2TorchMetricmAP
      update:
        pred_boxes: pred_bbox
        pred_scores: pred_score
        target_boxes: target_bbox
        target_labels: target_label
    total_loss:
      when: "trn"
      name: TorchMetric
      args:
        name: "MeanMetric"
      update:
        value: "loss"
    classification-accuracy:
      when: "trn"
      name: TorchMetric
      args:
        name: "MeanMetric"
      update:
        value: "acc"
    loss/rpn_cls:
      when: "trn"
      name: TorchMetric
      args:
        name: "MeanMetric"
      update:
        value: "loss_rpn_cls"
    loss/rpn_bbox:
      when: "trn"
      name: TorchMetric
      args:
        name: "MeanMetric"
      update:
        value: "loss_rpn_bbox"
    loss/bbox_reg:
      when: "trn"
      name: TorchMetric
      args:
        name: "MeanMetric"
      update:
        value: "loss_bbox"
    loss/classification:
      when: "trn"
      name: TorchMetric
      args:
        name: "MeanMetric"
      update:
        value: "loss_cls"

debug:
  view_train_augmentation:
    save_to: "vis/training_samples.png"
    subplot_dim: [4, 4]
    plot_size: 5

    is_01: False
    normalization_mean: "{const.normalization_mean}"
    normalization_std: "{const.normalization_std}"

    is_xywh: False
    bbox_unnormalization: False
    preprocess_f: convert-mmdetbbox

callbacks:
  ModelCheckpoint:
    name: LightningCallback
    args:
      name: ModelCheckpoint
      args:
        monitor: "epoch_val/mAP/map"
        mode: "max"
        save_last: True
        save_top_k: 1
  LearningRateMonitor:
    name: LightningCallback
    args:
      name: "LearningRateMonitor"
      args:
        logging_interval: "epoch"

dataloader:
  base_dataloader: # depends on hardware:)
    sampler: null
    batch_sampler: null
    num_workers: "2*{const.num_gpus}"
    pin_memory: True
    collate_fn:
      name: mmcv_datacontainer_collate
  trn:
    batch_size: "{const.samples_per_gpu}*{const.num_gpus}"
    shuffle: True
    # Extend default_collate to add support for:type:`~mmcv.parallel.DataContainer`.
  val:
    batch_size: "{const.val_samples_per_gpu}*{const.num_gpus}"
    shuffle: False
  test:
    batch_size: "{const.val_samples_per_gpu}*{const.num_gpus}"
    shuffle: False
