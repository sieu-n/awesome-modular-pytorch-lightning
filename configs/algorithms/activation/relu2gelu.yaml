# https://pytorch.org/docs/stable/generated/torch.nn.GELU.html
# Activation function proposed in the paper:
# Gaussian Error Linear Units (GELUs)
model:
  init_hook:
    change-activation:
      name: "ReplaceModulesOfType"
      args:
        subject_modules: "ReLU"
        subject_files: "torch.nn"
        target_module:
          name: "GELU"
          file: "torch.nn"
