# Knowledge distillation

Implements the following methods for knowledge distillation

- (KD): Distilling the Knowledge in a Neural Network
- (MSE): Comparing Kullback-Leibler Divergence and Mean Squared Error Loss
in Knowledge Distillation
